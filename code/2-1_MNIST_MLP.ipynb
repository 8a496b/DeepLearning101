{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 1. 모듈 임포트 '''\n",
    "import numpy as np                                     # (1)\n",
    "import matplotlib.pyplot as plt                        # (2)\n",
    "\n",
    "import torch                                           # (3)\n",
    "import torch.nn as nn                                  # (4)\n",
    "import torch.nn.functional as F                        # (5)\n",
    "from torchvision import transforms, datasets           # (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.5.0+cu101  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "''' 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인 '''\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32    # (1)\n",
    "EPOCHS = 10        # (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 3. MNIST 데이터 다운로드 (Train set, Test set 분리하기) '''\n",
    "train_dataset = datasets.MNIST(root = \"../data/MNIST\",                    # (1)\n",
    "                               train = True,\n",
    "                               download = True,\n",
    "                               transform = transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.MNIST(root = '../data/MNIST',                     # (2)\n",
    "                              train = False,\n",
    "                              transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,    # (3) \n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,      # (4)  \n",
    "                                          batch_size = BATCH_SIZE, \n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "''' 4. 데이터 확인하기 (1) '''\n",
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' 4. 데이터 확인하기 (2) '''\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap = \"gray_r\")\n",
    "    plt.title('Class: ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 5. MLP (Multi Layer Perceptron) 모델 설계하기 '''\n",
    "class Net(nn.Module):                         # (1)\n",
    "    def __init__(self):                       # (2)\n",
    "        super(Net, self).__init__()           # (3)\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)    # (4)\n",
    "        self.fc2 = nn.Linear(512, 256)        # (5)\n",
    "        self.fc3 = nn.Linear(256, 10)         # (6)\n",
    "    \n",
    "    def forward(self, x):                     # (7)\n",
    "        x = x.view(-1, 28 * 28)               # (8)\n",
    "        x = self.fc1(x)                       # (9)\n",
    "        x = F.sigmoid(x)                      # (10)\n",
    "        x = self.fc2(x)                       # (11)\n",
    "        x = F.sigmoid(x)                      # (12)\n",
    "        x = self.fc3(x)                       # (13)\n",
    "        x = F.log_softmax(x, dim = 1)         # (14)\n",
    "        return x                              # (15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "''' 6. Optimizer, Objective Function 설정하기 '''\n",
    "model = Net().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 7. MLP 학습, Test 성능 확인하는 함수 정의 '''\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "    return valid_loss, valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tTrain Loss: 2.424196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/101/lib/python3.6/site-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6400/60000 (11%)]\tTrain Loss: 2.344201\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tTrain Loss: 2.312999\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tTrain Loss: 2.287645\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tTrain Loss: 2.272641\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tTrain Loss: 2.283491\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tTrain Loss: 2.266382\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tTrain Loss: 2.297897\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tTrain Loss: 2.247268\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tTrain Loss: 2.276688\n",
      "\n",
      "[EPOCH: 1], \tValidation Loss: 0.0701, \tValidation Accuracy: 10.32 % \n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tTrain Loss: 2.221574\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tTrain Loss: 2.243536\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tTrain Loss: 2.157095\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tTrain Loss: 2.112867\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tTrain Loss: 1.997795\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tTrain Loss: 1.931436\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tTrain Loss: 1.716713\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tTrain Loss: 1.586588\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tTrain Loss: 1.235298\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tTrain Loss: 1.359767\n",
      "\n",
      "[EPOCH: 2], \tValidation Loss: 0.0398, \tValidation Accuracy: 62.28 % \n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tTrain Loss: 1.219643\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tTrain Loss: 1.124387\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tTrain Loss: 1.044094\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tTrain Loss: 1.173632\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tTrain Loss: 1.063740\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tTrain Loss: 1.041374\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tTrain Loss: 0.924785\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tTrain Loss: 1.024535\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tTrain Loss: 0.474586\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tTrain Loss: 0.561199\n",
      "\n",
      "[EPOCH: 3], \tValidation Loss: 0.0232, \tValidation Accuracy: 78.27 % \n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tTrain Loss: 0.516723\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tTrain Loss: 0.728862\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tTrain Loss: 0.752865\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tTrain Loss: 0.643220\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tTrain Loss: 0.556849\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tTrain Loss: 0.712711\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tTrain Loss: 0.498014\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tTrain Loss: 0.557761\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tTrain Loss: 0.385865\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tTrain Loss: 0.548725\n",
      "\n",
      "[EPOCH: 4], \tValidation Loss: 0.0169, \tValidation Accuracy: 84.46 % \n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tTrain Loss: 0.504611\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tTrain Loss: 0.320598\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tTrain Loss: 0.414609\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tTrain Loss: 0.629752\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tTrain Loss: 0.315901\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tTrain Loss: 0.566069\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tTrain Loss: 0.424472\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tTrain Loss: 0.653903\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tTrain Loss: 0.259283\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tTrain Loss: 0.271441\n",
      "\n",
      "[EPOCH: 5], \tValidation Loss: 0.0141, \tValidation Accuracy: 86.97 % \n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tTrain Loss: 0.317507\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tTrain Loss: 0.416920\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tTrain Loss: 0.596478\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tTrain Loss: 0.307686\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tTrain Loss: 0.473826\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tTrain Loss: 0.724353\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tTrain Loss: 0.653290\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tTrain Loss: 0.683536\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tTrain Loss: 0.210763\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tTrain Loss: 0.457441\n",
      "\n",
      "[EPOCH: 6], \tValidation Loss: 0.0125, \tValidation Accuracy: 88.53 % \n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tTrain Loss: 0.342045\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tTrain Loss: 0.556904\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tTrain Loss: 0.226097\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tTrain Loss: 0.466696\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tTrain Loss: 0.302342\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tTrain Loss: 0.250243\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tTrain Loss: 0.417939\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tTrain Loss: 0.415744\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tTrain Loss: 0.288004\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tTrain Loss: 0.487591\n",
      "\n",
      "[EPOCH: 7], \tValidation Loss: 0.0117, \tValidation Accuracy: 89.12 % \n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tTrain Loss: 0.443901\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tTrain Loss: 0.258660\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tTrain Loss: 0.360272\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tTrain Loss: 0.191860\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tTrain Loss: 0.403571\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tTrain Loss: 0.257717\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tTrain Loss: 0.320336\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tTrain Loss: 0.400189\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tTrain Loss: 0.230428\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tTrain Loss: 0.252461\n",
      "\n",
      "[EPOCH: 8], \tValidation Loss: 0.0112, \tValidation Accuracy: 89.41 % \n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tTrain Loss: 0.567175\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tTrain Loss: 0.296187\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tTrain Loss: 0.514285\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tTrain Loss: 0.487202\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tTrain Loss: 0.237936\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tTrain Loss: 0.452177\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tTrain Loss: 0.150447\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tTrain Loss: 0.323894\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tTrain Loss: 0.504614\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tTrain Loss: 0.406327\n",
      "\n",
      "[EPOCH: 9], \tValidation Loss: 0.0108, \tValidation Accuracy: 90.00 % \n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tTrain Loss: 0.241556\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tTrain Loss: 0.476289\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tTrain Loss: 0.272307\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tTrain Loss: 0.326179\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tTrain Loss: 0.346531\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tTrain Loss: 0.348978\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tTrain Loss: 0.469928\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tTrain Loss: 0.639160\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tTrain Loss: 0.631226\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tTrain Loss: 0.172581\n",
      "\n",
      "[EPOCH: 10], \tValidation Loss: 0.0104, \tValidation Accuracy: 90.28 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' 8. MLP 학습 실행 '''\n",
    "''' 9. EPOCH 별 Test set Loss 및 Test set Accuracy 확인하기 '''\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    valid_loss, valid_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tValidation Loss: {:.4f}, \\tValidation Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, valid_loss, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/101/lib/python3.6/site-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tTrain Loss: 2.342009\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tTrain Loss: 2.307410\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tTrain Loss: 2.276745\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tTrain Loss: 2.305777\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tTrain Loss: 2.318694\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tTrain Loss: 2.246972\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tTrain Loss: 2.275294\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tTrain Loss: 2.250535\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tTrain Loss: 2.234854\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tTrain Loss: 2.231340\n",
      "\n",
      "[EPOCH: 1], \tValidation Loss: 0.0697, \tValidation Accuracy: 22.13 % \n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tTrain Loss: 2.248917\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tTrain Loss: 2.202651\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tTrain Loss: 2.245512\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tTrain Loss: 2.035278\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tTrain Loss: 2.028179\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tTrain Loss: 1.784670\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tTrain Loss: 1.472483\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tTrain Loss: 1.241071\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tTrain Loss: 1.471806\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tTrain Loss: 1.305039\n",
      "\n",
      "[EPOCH: 2], \tValidation Loss: 0.0380, \tValidation Accuracy: 65.21 % \n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tTrain Loss: 1.209522\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tTrain Loss: 1.287589\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tTrain Loss: 1.156216\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tTrain Loss: 1.166106\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tTrain Loss: 0.831335\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tTrain Loss: 0.994648\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tTrain Loss: 0.764767\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tTrain Loss: 0.722380\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tTrain Loss: 0.569633\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tTrain Loss: 0.846207\n",
      "\n",
      "[EPOCH: 3], \tValidation Loss: 0.0228, \tValidation Accuracy: 77.04 % \n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tTrain Loss: 0.918441\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tTrain Loss: 0.524642\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tTrain Loss: 1.154924\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tTrain Loss: 0.784420\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tTrain Loss: 0.622072\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tTrain Loss: 0.476990\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tTrain Loss: 0.721564\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tTrain Loss: 0.561709\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tTrain Loss: 0.580571\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tTrain Loss: 0.587558\n",
      "\n",
      "[EPOCH: 4], \tValidation Loss: 0.0168, \tValidation Accuracy: 84.31 % \n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tTrain Loss: 0.448198\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tTrain Loss: 0.702511\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tTrain Loss: 0.433601\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tTrain Loss: 0.304108\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tTrain Loss: 0.374309\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tTrain Loss: 0.392352\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tTrain Loss: 1.004600\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tTrain Loss: 0.475475\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tTrain Loss: 0.435117\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tTrain Loss: 0.273347\n",
      "\n",
      "[EPOCH: 5], \tValidation Loss: 0.0142, \tValidation Accuracy: 86.77 % \n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tTrain Loss: 0.226375\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tTrain Loss: 0.194259\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tTrain Loss: 0.575185\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tTrain Loss: 0.388831\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tTrain Loss: 0.302748\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tTrain Loss: 0.357837\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tTrain Loss: 0.302870\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tTrain Loss: 0.331007\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tTrain Loss: 0.466938\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tTrain Loss: 0.624737\n",
      "\n",
      "[EPOCH: 6], \tValidation Loss: 0.0131, \tValidation Accuracy: 87.47 % \n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tTrain Loss: 0.376542\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tTrain Loss: 0.682902\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tTrain Loss: 0.418133\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tTrain Loss: 0.365469\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tTrain Loss: 0.186929\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tTrain Loss: 0.376582\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tTrain Loss: 0.560606\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tTrain Loss: 0.369687\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tTrain Loss: 0.547295\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tTrain Loss: 0.358212\n",
      "\n",
      "[EPOCH: 7], \tValidation Loss: 0.0121, \tValidation Accuracy: 88.91 % \n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tTrain Loss: 0.249865\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tTrain Loss: 0.337978\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tTrain Loss: 0.216573\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tTrain Loss: 0.503669\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tTrain Loss: 0.520924\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tTrain Loss: 0.717088\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tTrain Loss: 0.317214\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tTrain Loss: 0.479086\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tTrain Loss: 0.273334\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tTrain Loss: 0.283964\n",
      "\n",
      "[EPOCH: 8], \tValidation Loss: 0.0115, \tValidation Accuracy: 89.46 % \n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tTrain Loss: 0.307942\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tTrain Loss: 0.252169\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tTrain Loss: 0.384129\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tTrain Loss: 0.282773\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tTrain Loss: 0.576020\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tTrain Loss: 0.267511\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tTrain Loss: 0.388576\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tTrain Loss: 0.222164\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tTrain Loss: 0.548319\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tTrain Loss: 0.248616\n",
      "\n",
      "[EPOCH: 9], \tValidation Loss: 0.0110, \tValidation Accuracy: 89.63 % \n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tTrain Loss: 0.215696\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tTrain Loss: 0.552467\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tTrain Loss: 0.527105\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tTrain Loss: 0.412108\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tTrain Loss: 0.504321\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tTrain Loss: 0.321950\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tTrain Loss: 0.593067\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tTrain Loss: 0.331363\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tTrain Loss: 0.176321\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tTrain Loss: 0.334046\n",
      "\n",
      "[EPOCH: 10], \tValidation Loss: 0.0106, \tValidation Accuracy: 90.09 % \n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tTrain Loss: 0.296688\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tTrain Loss: 0.187242\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tTrain Loss: 0.411868\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tTrain Loss: 0.989796\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tTrain Loss: 0.320846\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tTrain Loss: 0.504821\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tTrain Loss: 0.250688\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tTrain Loss: 0.454098\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tTrain Loss: 0.433578\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tTrain Loss: 0.223969\n",
      "\n",
      "[EPOCH: 11], \tValidation Loss: 0.0103, \tValidation Accuracy: 90.43 % \n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tTrain Loss: 0.328282\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tTrain Loss: 0.305401\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tTrain Loss: 0.304826\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tTrain Loss: 0.436023\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tTrain Loss: 0.261093\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tTrain Loss: 0.273624\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tTrain Loss: 0.149664\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tTrain Loss: 0.264230\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tTrain Loss: 0.500930\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tTrain Loss: 0.103657\n",
      "\n",
      "[EPOCH: 12], \tValidation Loss: 0.0101, \tValidation Accuracy: 90.46 % \n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tTrain Loss: 0.310282\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tTrain Loss: 0.208619\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tTrain Loss: 0.277436\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tTrain Loss: 0.338891\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tTrain Loss: 0.250409\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tTrain Loss: 0.326147\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tTrain Loss: 0.429831\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tTrain Loss: 0.535919\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tTrain Loss: 0.233972\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tTrain Loss: 0.494316\n",
      "\n",
      "[EPOCH: 13], \tValidation Loss: 0.0099, \tValidation Accuracy: 90.76 % \n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tTrain Loss: 0.120151\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tTrain Loss: 0.466320\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tTrain Loss: 0.415670\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tTrain Loss: 0.650126\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tTrain Loss: 0.127205\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tTrain Loss: 0.128556\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tTrain Loss: 0.389157\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tTrain Loss: 0.155082\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tTrain Loss: 0.339491\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tTrain Loss: 0.461122\n",
      "\n",
      "[EPOCH: 14], \tValidation Loss: 0.0095, \tValidation Accuracy: 91.18 % \n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tTrain Loss: 0.545378\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tTrain Loss: 0.199383\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tTrain Loss: 0.233941\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tTrain Loss: 0.411687\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tTrain Loss: 0.210786\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tTrain Loss: 0.281112\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tTrain Loss: 0.278834\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tTrain Loss: 0.436060\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tTrain Loss: 0.418297\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tTrain Loss: 0.321915\n",
      "\n",
      "[EPOCH: 15], \tValidation Loss: 0.0093, \tValidation Accuracy: 91.49 % \n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tTrain Loss: 0.435174\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tTrain Loss: 0.263018\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tTrain Loss: 0.164043\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tTrain Loss: 0.766519\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tTrain Loss: 0.377310\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tTrain Loss: 0.326234\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tTrain Loss: 0.124442\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tTrain Loss: 0.601173\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tTrain Loss: 0.080436\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tTrain Loss: 0.153095\n",
      "\n",
      "[EPOCH: 16], \tValidation Loss: 0.0093, \tValidation Accuracy: 91.39 % \n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tTrain Loss: 0.174884\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tTrain Loss: 0.214282\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tTrain Loss: 0.236824\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tTrain Loss: 0.291502\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tTrain Loss: 0.084683\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tTrain Loss: 0.144068\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tTrain Loss: 0.228142\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tTrain Loss: 0.211551\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tTrain Loss: 0.305507\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tTrain Loss: 0.448714\n",
      "\n",
      "[EPOCH: 17], \tValidation Loss: 0.0090, \tValidation Accuracy: 91.54 % \n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tTrain Loss: 0.355918\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tTrain Loss: 0.308713\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tTrain Loss: 0.153375\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tTrain Loss: 0.278694\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tTrain Loss: 0.290190\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tTrain Loss: 0.299550\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tTrain Loss: 0.299831\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tTrain Loss: 0.187946\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tTrain Loss: 0.385971\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tTrain Loss: 0.122403\n",
      "\n",
      "[EPOCH: 18], \tValidation Loss: 0.0088, \tValidation Accuracy: 91.87 % \n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tTrain Loss: 0.474258\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tTrain Loss: 0.199353\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tTrain Loss: 0.106716\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tTrain Loss: 0.083647\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tTrain Loss: 0.091550\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tTrain Loss: 0.426824\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tTrain Loss: 0.486041\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tTrain Loss: 0.188205\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tTrain Loss: 0.221050\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tTrain Loss: 0.415751\n",
      "\n",
      "[EPOCH: 19], \tValidation Loss: 0.0088, \tValidation Accuracy: 91.83 % \n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tTrain Loss: 0.268235\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tTrain Loss: 0.264644\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tTrain Loss: 0.333093\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tTrain Loss: 0.331354\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tTrain Loss: 0.169482\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tTrain Loss: 0.338422\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tTrain Loss: 0.230870\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tTrain Loss: 0.385613\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tTrain Loss: 0.147132\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tTrain Loss: 0.354683\n",
      "\n",
      "[EPOCH: 20], \tValidation Loss: 0.0085, \tValidation Accuracy: 91.95 % \n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tTrain Loss: 0.083235\n",
      "Train Epoch: 21 [6400/60000 (11%)]\tTrain Loss: 0.162055\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tTrain Loss: 0.145462\n",
      "Train Epoch: 21 [19200/60000 (32%)]\tTrain Loss: 0.217598\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tTrain Loss: 0.231049\n",
      "Train Epoch: 21 [32000/60000 (53%)]\tTrain Loss: 0.521513\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tTrain Loss: 0.286405\n",
      "Train Epoch: 21 [44800/60000 (75%)]\tTrain Loss: 0.253238\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tTrain Loss: 0.180341\n",
      "Train Epoch: 21 [57600/60000 (96%)]\tTrain Loss: 0.522448\n",
      "\n",
      "[EPOCH: 21], \tValidation Loss: 0.0084, \tValidation Accuracy: 92.27 % \n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tTrain Loss: 0.232624\n",
      "Train Epoch: 22 [6400/60000 (11%)]\tTrain Loss: 0.349008\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tTrain Loss: 0.240960\n",
      "Train Epoch: 22 [19200/60000 (32%)]\tTrain Loss: 0.306377\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tTrain Loss: 0.189109\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tTrain Loss: 0.370815\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tTrain Loss: 0.098523\n",
      "Train Epoch: 22 [44800/60000 (75%)]\tTrain Loss: 0.514340\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tTrain Loss: 0.136767\n",
      "Train Epoch: 22 [57600/60000 (96%)]\tTrain Loss: 0.374158\n",
      "\n",
      "[EPOCH: 22], \tValidation Loss: 0.0082, \tValidation Accuracy: 92.38 % \n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tTrain Loss: 0.222837\n",
      "Train Epoch: 23 [6400/60000 (11%)]\tTrain Loss: 0.239603\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tTrain Loss: 0.240256\n",
      "Train Epoch: 23 [19200/60000 (32%)]\tTrain Loss: 0.166926\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tTrain Loss: 0.192260\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tTrain Loss: 0.222080\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tTrain Loss: 0.102882\n",
      "Train Epoch: 23 [44800/60000 (75%)]\tTrain Loss: 0.306369\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tTrain Loss: 0.183340\n",
      "Train Epoch: 23 [57600/60000 (96%)]\tTrain Loss: 0.133721\n",
      "\n",
      "[EPOCH: 23], \tValidation Loss: 0.0080, \tValidation Accuracy: 92.47 % \n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tTrain Loss: 0.351106\n",
      "Train Epoch: 24 [6400/60000 (11%)]\tTrain Loss: 0.237856\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tTrain Loss: 0.113124\n",
      "Train Epoch: 24 [19200/60000 (32%)]\tTrain Loss: 0.270082\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tTrain Loss: 0.354734\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tTrain Loss: 0.416699\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tTrain Loss: 0.046119\n",
      "Train Epoch: 24 [44800/60000 (75%)]\tTrain Loss: 0.185425\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tTrain Loss: 0.093411\n",
      "Train Epoch: 24 [57600/60000 (96%)]\tTrain Loss: 0.187366\n",
      "\n",
      "[EPOCH: 24], \tValidation Loss: 0.0079, \tValidation Accuracy: 92.63 % \n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tTrain Loss: 0.223118\n",
      "Train Epoch: 25 [6400/60000 (11%)]\tTrain Loss: 0.100091\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tTrain Loss: 0.207096\n",
      "Train Epoch: 25 [19200/60000 (32%)]\tTrain Loss: 0.218159\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tTrain Loss: 0.165462\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tTrain Loss: 0.201339\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tTrain Loss: 0.359512\n",
      "Train Epoch: 25 [44800/60000 (75%)]\tTrain Loss: 0.136994\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tTrain Loss: 0.060733\n",
      "Train Epoch: 25 [57600/60000 (96%)]\tTrain Loss: 0.423268\n",
      "\n",
      "[EPOCH: 25], \tValidation Loss: 0.0077, \tValidation Accuracy: 92.76 % \n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tTrain Loss: 0.164893\n",
      "Train Epoch: 26 [6400/60000 (11%)]\tTrain Loss: 0.251964\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tTrain Loss: 0.197245\n",
      "Train Epoch: 26 [19200/60000 (32%)]\tTrain Loss: 0.215012\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tTrain Loss: 0.238786\n",
      "Train Epoch: 26 [32000/60000 (53%)]\tTrain Loss: 0.090580\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tTrain Loss: 0.149725\n",
      "Train Epoch: 26 [44800/60000 (75%)]\tTrain Loss: 0.187245\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tTrain Loss: 0.328441\n",
      "Train Epoch: 26 [57600/60000 (96%)]\tTrain Loss: 0.170736\n",
      "\n",
      "[EPOCH: 26], \tValidation Loss: 0.0076, \tValidation Accuracy: 93.05 % \n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tTrain Loss: 0.463298\n",
      "Train Epoch: 27 [6400/60000 (11%)]\tTrain Loss: 0.359363\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tTrain Loss: 0.189843\n",
      "Train Epoch: 27 [19200/60000 (32%)]\tTrain Loss: 0.287216\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tTrain Loss: 0.152648\n",
      "Train Epoch: 27 [32000/60000 (53%)]\tTrain Loss: 0.260206\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tTrain Loss: 0.291793\n",
      "Train Epoch: 27 [44800/60000 (75%)]\tTrain Loss: 0.210248\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tTrain Loss: 0.266885\n",
      "Train Epoch: 27 [57600/60000 (96%)]\tTrain Loss: 0.257656\n",
      "\n",
      "[EPOCH: 27], \tValidation Loss: 0.0075, \tValidation Accuracy: 92.97 % \n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tTrain Loss: 0.120596\n",
      "Train Epoch: 28 [6400/60000 (11%)]\tTrain Loss: 0.129003\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tTrain Loss: 0.139764\n",
      "Train Epoch: 28 [19200/60000 (32%)]\tTrain Loss: 0.614969\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tTrain Loss: 0.121914\n",
      "Train Epoch: 28 [32000/60000 (53%)]\tTrain Loss: 0.146170\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tTrain Loss: 0.492421\n",
      "Train Epoch: 28 [44800/60000 (75%)]\tTrain Loss: 0.201558\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tTrain Loss: 0.258342\n",
      "Train Epoch: 28 [57600/60000 (96%)]\tTrain Loss: 0.137600\n",
      "\n",
      "[EPOCH: 28], \tValidation Loss: 0.0074, \tValidation Accuracy: 93.08 % \n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tTrain Loss: 0.084408\n",
      "Train Epoch: 29 [6400/60000 (11%)]\tTrain Loss: 0.080307\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tTrain Loss: 0.266262\n",
      "Train Epoch: 29 [19200/60000 (32%)]\tTrain Loss: 0.225057\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tTrain Loss: 0.073361\n",
      "Train Epoch: 29 [32000/60000 (53%)]\tTrain Loss: 0.098985\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tTrain Loss: 0.407715\n",
      "Train Epoch: 29 [44800/60000 (75%)]\tTrain Loss: 0.226865\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tTrain Loss: 0.335086\n",
      "Train Epoch: 29 [57600/60000 (96%)]\tTrain Loss: 0.160251\n",
      "\n",
      "[EPOCH: 29], \tValidation Loss: 0.0072, \tValidation Accuracy: 93.25 % \n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tTrain Loss: 0.288212\n",
      "Train Epoch: 30 [6400/60000 (11%)]\tTrain Loss: 0.081392\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tTrain Loss: 0.338684\n",
      "Train Epoch: 30 [19200/60000 (32%)]\tTrain Loss: 0.428935\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tTrain Loss: 0.174782\n",
      "Train Epoch: 30 [32000/60000 (53%)]\tTrain Loss: 0.117063\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tTrain Loss: 0.461540\n",
      "Train Epoch: 30 [44800/60000 (75%)]\tTrain Loss: 0.346205\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tTrain Loss: 0.094038\n",
      "Train Epoch: 30 [57600/60000 (96%)]\tTrain Loss: 0.377857\n",
      "\n",
      "[EPOCH: 30], \tValidation Loss: 0.0071, \tValidation Accuracy: 93.30 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' 8. MLP 학습 실행 '''\n",
    "''' 9. EPOCH 별 Test set Loss 및 Test set Accuracy 확인하기 '''\n",
    "for epoch in range(1, 31):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    valid_loss, valid_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tValidation Loss: {:.4f}, \\tValidation Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, valid_loss, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
