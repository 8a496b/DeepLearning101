{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 1. 모듈 임포트 '''\n",
    "import numpy as np                                     # (1)\n",
    "import matplotlib.pyplot as plt                        # (2)\n",
    "import torch                                           # (3)\n",
    "import torch.nn as nn                                  # (4)\n",
    "import torch.nn.functional as F                        # (5)\n",
    "from torchvision import transforms, datasets           # (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.5.0+cu101  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "''' 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인 '''\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32    # (1)\n",
    "EPOCHS = 30        # (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 3. MNIST 데이터 다운로드 (Train set, Test set 분리하기) '''\n",
    "train_dataset = datasets.MNIST(root = \"../data/MNIST\",                    # (1)\n",
    "                               train = True,\n",
    "                               download = True,\n",
    "                               transform = transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.MNIST(root = '../data/MNIST',                     # (2)\n",
    "                              train = False,\n",
    "                              transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,    # (3) \n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,      # (4)  \n",
    "                                          batch_size = BATCH_SIZE, \n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "''' 4. 데이터 확인하기 (1) '''\n",
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' 4. 데이터 확인하기 (2) '''\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap = \"gray_r\")\n",
    "    plt.title('Class: ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 5. MLP (Multi Layer Perceptron) 모델 설계하기 '''\n",
    "class Net(nn.Module):                         # (1)\n",
    "    def __init__(self):                       # (2)\n",
    "        super(Net, self).__init__()           # (3)\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)    # (4)\n",
    "        self.fc2 = nn.Linear(512, 256)        # (5)\n",
    "        self.fc3 = nn.Linear(256, 10)         # (6)\n",
    "        self.dropout_prob = 0.5\n",
    "    \n",
    "    def forward(self, x):                     # (7)\n",
    "        x = x.view(-1, 28 * 28)               # (8)\n",
    "        x = self.fc1(x)                       # (9)\n",
    "        x = F.sigmoid(x)                      # (10)\n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob)\n",
    "        x = self.fc2(x)                       # (11)\n",
    "        x = F.sigmoid(x)                      # (12)\n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob)\n",
    "        x = self.fc3(x)                       # (13)\n",
    "        x = F.log_softmax(x, dim = 1)         # (14)\n",
    "        return x                              # (15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "''' 6. Optimizer, Objective Function 설정하기 '''\n",
    "model = Net().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 7. MLP 학습, Test 성능 확인하는 함수 정의 '''\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "    return valid_loss, valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tTrain Loss: 2.356083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/101/lib/python3.6/site-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6400/60000 (11%)]\tTrain Loss: 2.373342\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tTrain Loss: 2.338788\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tTrain Loss: 2.378286\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tTrain Loss: 2.299438\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tTrain Loss: 2.332760\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tTrain Loss: 2.300584\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tTrain Loss: 2.300132\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tTrain Loss: 2.359423\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tTrain Loss: 2.274001\n",
      "\n",
      "[EPOCH: 1], \tValidation Loss: 0.0714, \tValidation Accuracy: 13.24 % \n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tTrain Loss: 2.274102\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tTrain Loss: 2.292180\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tTrain Loss: 2.232202\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tTrain Loss: 2.267287\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tTrain Loss: 2.289592\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tTrain Loss: 2.268329\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tTrain Loss: 2.218315\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tTrain Loss: 2.147727\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tTrain Loss: 2.022791\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tTrain Loss: 2.210429\n",
      "\n",
      "[EPOCH: 2], \tValidation Loss: 0.0626, \tValidation Accuracy: 37.97 % \n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tTrain Loss: 2.049360\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tTrain Loss: 1.951492\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tTrain Loss: 2.008311\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tTrain Loss: 1.798092\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tTrain Loss: 1.818315\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tTrain Loss: 1.585153\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tTrain Loss: 1.519253\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tTrain Loss: 1.543647\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tTrain Loss: 1.388616\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tTrain Loss: 1.183509\n",
      "\n",
      "[EPOCH: 3], \tValidation Loss: 0.0370, \tValidation Accuracy: 63.24 % \n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tTrain Loss: 1.241023\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tTrain Loss: 1.131032\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tTrain Loss: 1.045713\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tTrain Loss: 1.269837\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tTrain Loss: 1.132532\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tTrain Loss: 1.424263\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tTrain Loss: 1.308532\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tTrain Loss: 1.427311\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tTrain Loss: 1.159400\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tTrain Loss: 0.783421\n",
      "\n",
      "[EPOCH: 4], \tValidation Loss: 0.0274, \tValidation Accuracy: 69.47 % \n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tTrain Loss: 1.452472\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tTrain Loss: 1.148528\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tTrain Loss: 0.702382\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tTrain Loss: 0.869500\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tTrain Loss: 1.297290\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tTrain Loss: 1.087825\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tTrain Loss: 0.984033\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tTrain Loss: 1.162911\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tTrain Loss: 0.620948\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tTrain Loss: 0.787981\n",
      "\n",
      "[EPOCH: 5], \tValidation Loss: 0.0237, \tValidation Accuracy: 76.21 % \n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tTrain Loss: 0.921765\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tTrain Loss: 0.527534\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tTrain Loss: 0.753540\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tTrain Loss: 1.277788\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tTrain Loss: 0.775037\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tTrain Loss: 0.762685\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tTrain Loss: 0.984695\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tTrain Loss: 0.850065\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tTrain Loss: 0.785509\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tTrain Loss: 0.748225\n",
      "\n",
      "[EPOCH: 6], \tValidation Loss: 0.0210, \tValidation Accuracy: 79.59 % \n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tTrain Loss: 0.491637\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tTrain Loss: 0.805111\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tTrain Loss: 0.772314\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tTrain Loss: 0.699869\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tTrain Loss: 0.975398\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tTrain Loss: 0.767328\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tTrain Loss: 0.896827\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tTrain Loss: 0.793246\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tTrain Loss: 0.648995\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tTrain Loss: 0.572963\n",
      "\n",
      "[EPOCH: 7], \tValidation Loss: 0.0187, \tValidation Accuracy: 82.52 % \n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tTrain Loss: 0.549929\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tTrain Loss: 0.893511\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tTrain Loss: 0.683265\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tTrain Loss: 0.529942\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tTrain Loss: 1.043084\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tTrain Loss: 0.902501\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tTrain Loss: 0.656618\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tTrain Loss: 0.549823\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tTrain Loss: 0.467533\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tTrain Loss: 0.419303\n",
      "\n",
      "[EPOCH: 8], \tValidation Loss: 0.0168, \tValidation Accuracy: 84.09 % \n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tTrain Loss: 0.600516\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tTrain Loss: 0.543444\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tTrain Loss: 1.237001\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tTrain Loss: 0.696220\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tTrain Loss: 0.842042\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tTrain Loss: 0.553536\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tTrain Loss: 0.510284\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tTrain Loss: 0.515367\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tTrain Loss: 0.578566\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tTrain Loss: 0.361014\n",
      "\n",
      "[EPOCH: 9], \tValidation Loss: 0.0154, \tValidation Accuracy: 85.30 % \n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tTrain Loss: 0.762817\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tTrain Loss: 0.542002\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tTrain Loss: 0.849984\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tTrain Loss: 0.594872\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tTrain Loss: 0.597708\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tTrain Loss: 0.556241\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tTrain Loss: 0.542729\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tTrain Loss: 0.817507\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tTrain Loss: 0.489557\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tTrain Loss: 0.529815\n",
      "\n",
      "[EPOCH: 10], \tValidation Loss: 0.0144, \tValidation Accuracy: 86.44 % \n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tTrain Loss: 0.947306\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tTrain Loss: 0.570150\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tTrain Loss: 0.394609\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tTrain Loss: 0.428758\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tTrain Loss: 0.341591\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tTrain Loss: 0.596015\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tTrain Loss: 1.004970\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tTrain Loss: 0.524367\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tTrain Loss: 0.981996\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tTrain Loss: 0.464526\n",
      "\n",
      "[EPOCH: 11], \tValidation Loss: 0.0135, \tValidation Accuracy: 87.38 % \n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tTrain Loss: 0.330765\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tTrain Loss: 0.579915\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tTrain Loss: 0.370322\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tTrain Loss: 0.680818\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tTrain Loss: 0.751874\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tTrain Loss: 0.785514\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tTrain Loss: 0.728858\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tTrain Loss: 0.529312\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tTrain Loss: 0.433864\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tTrain Loss: 0.553698\n",
      "\n",
      "[EPOCH: 12], \tValidation Loss: 0.0129, \tValidation Accuracy: 87.86 % \n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tTrain Loss: 1.037603\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tTrain Loss: 0.418061\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tTrain Loss: 0.307952\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tTrain Loss: 0.402297\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tTrain Loss: 0.525614\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tTrain Loss: 0.443775\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tTrain Loss: 0.422818\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tTrain Loss: 0.424662\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tTrain Loss: 0.440455\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tTrain Loss: 0.627658\n",
      "\n",
      "[EPOCH: 13], \tValidation Loss: 0.0123, \tValidation Accuracy: 88.35 % \n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tTrain Loss: 0.439236\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tTrain Loss: 0.744511\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tTrain Loss: 0.862981\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tTrain Loss: 0.339117\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tTrain Loss: 0.364868\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tTrain Loss: 0.444283\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tTrain Loss: 0.639020\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tTrain Loss: 0.630930\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tTrain Loss: 0.427719\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tTrain Loss: 0.415060\n",
      "\n",
      "[EPOCH: 14], \tValidation Loss: 0.0119, \tValidation Accuracy: 88.62 % \n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tTrain Loss: 0.478065\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tTrain Loss: 0.494797\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tTrain Loss: 0.606411\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tTrain Loss: 0.303266\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tTrain Loss: 0.212494\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tTrain Loss: 0.606939\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tTrain Loss: 0.377268\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tTrain Loss: 0.640668\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tTrain Loss: 0.350480\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tTrain Loss: 0.647225\n",
      "\n",
      "[EPOCH: 15], \tValidation Loss: 0.0115, \tValidation Accuracy: 89.00 % \n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tTrain Loss: 0.570595\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tTrain Loss: 0.179770\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tTrain Loss: 0.723245\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tTrain Loss: 0.282712\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tTrain Loss: 0.287381\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tTrain Loss: 0.530907\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tTrain Loss: 0.593948\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tTrain Loss: 0.253934\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tTrain Loss: 0.396970\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tTrain Loss: 0.535030\n",
      "\n",
      "[EPOCH: 16], \tValidation Loss: 0.0112, \tValidation Accuracy: 89.19 % \n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tTrain Loss: 0.300091\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tTrain Loss: 0.408037\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tTrain Loss: 0.159372\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tTrain Loss: 0.424243\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tTrain Loss: 0.288056\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tTrain Loss: 0.732342\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tTrain Loss: 0.964282\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tTrain Loss: 0.430998\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tTrain Loss: 0.487503\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tTrain Loss: 0.362615\n",
      "\n",
      "[EPOCH: 17], \tValidation Loss: 0.0110, \tValidation Accuracy: 89.44 % \n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tTrain Loss: 0.369750\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tTrain Loss: 0.535589\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tTrain Loss: 0.354526\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tTrain Loss: 0.527519\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tTrain Loss: 0.501297\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tTrain Loss: 0.278101\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tTrain Loss: 0.337543\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tTrain Loss: 0.429555\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tTrain Loss: 0.473181\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tTrain Loss: 0.289349\n",
      "\n",
      "[EPOCH: 18], \tValidation Loss: 0.0106, \tValidation Accuracy: 89.79 % \n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tTrain Loss: 0.691679\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tTrain Loss: 0.374253\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tTrain Loss: 0.828031\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tTrain Loss: 0.240004\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tTrain Loss: 0.350445\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tTrain Loss: 0.585797\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tTrain Loss: 0.474752\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tTrain Loss: 0.329804\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tTrain Loss: 0.330864\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tTrain Loss: 0.644409\n",
      "\n",
      "[EPOCH: 19], \tValidation Loss: 0.0104, \tValidation Accuracy: 90.02 % \n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tTrain Loss: 0.439276\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tTrain Loss: 0.278309\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tTrain Loss: 0.296266\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tTrain Loss: 0.299595\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tTrain Loss: 0.358263\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tTrain Loss: 0.590861\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tTrain Loss: 0.388973\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tTrain Loss: 0.376813\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tTrain Loss: 0.353996\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tTrain Loss: 0.721895\n",
      "\n",
      "[EPOCH: 20], \tValidation Loss: 0.0101, \tValidation Accuracy: 90.35 % \n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tTrain Loss: 0.325901\n",
      "Train Epoch: 21 [6400/60000 (11%)]\tTrain Loss: 0.148138\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tTrain Loss: 0.357305\n",
      "Train Epoch: 21 [19200/60000 (32%)]\tTrain Loss: 0.372382\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tTrain Loss: 0.367210\n",
      "Train Epoch: 21 [32000/60000 (53%)]\tTrain Loss: 0.323952\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tTrain Loss: 0.188575\n",
      "Train Epoch: 21 [44800/60000 (75%)]\tTrain Loss: 0.084431\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tTrain Loss: 0.469216\n",
      "Train Epoch: 21 [57600/60000 (96%)]\tTrain Loss: 0.304124\n",
      "\n",
      "[EPOCH: 21], \tValidation Loss: 0.0100, \tValidation Accuracy: 90.33 % \n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tTrain Loss: 0.614388\n",
      "Train Epoch: 22 [6400/60000 (11%)]\tTrain Loss: 0.617609\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tTrain Loss: 0.328463\n",
      "Train Epoch: 22 [19200/60000 (32%)]\tTrain Loss: 0.318507\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tTrain Loss: 0.613359\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tTrain Loss: 0.428673\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tTrain Loss: 0.484254\n",
      "Train Epoch: 22 [44800/60000 (75%)]\tTrain Loss: 0.497450\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tTrain Loss: 0.684605\n",
      "Train Epoch: 22 [57600/60000 (96%)]\tTrain Loss: 0.262665\n",
      "\n",
      "[EPOCH: 22], \tValidation Loss: 0.0097, \tValidation Accuracy: 90.59 % \n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tTrain Loss: 0.758110\n",
      "Train Epoch: 23 [6400/60000 (11%)]\tTrain Loss: 0.376193\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tTrain Loss: 0.344669\n",
      "Train Epoch: 23 [19200/60000 (32%)]\tTrain Loss: 0.256709\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tTrain Loss: 0.491285\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tTrain Loss: 0.371007\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tTrain Loss: 0.401855\n",
      "Train Epoch: 23 [44800/60000 (75%)]\tTrain Loss: 0.407134\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tTrain Loss: 0.221818\n",
      "Train Epoch: 23 [57600/60000 (96%)]\tTrain Loss: 0.138675\n",
      "\n",
      "[EPOCH: 23], \tValidation Loss: 0.0096, \tValidation Accuracy: 90.78 % \n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tTrain Loss: 0.236874\n",
      "Train Epoch: 24 [6400/60000 (11%)]\tTrain Loss: 0.488450\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tTrain Loss: 0.542601\n",
      "Train Epoch: 24 [19200/60000 (32%)]\tTrain Loss: 0.586471\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tTrain Loss: 0.459150\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tTrain Loss: 0.310461\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tTrain Loss: 0.146600\n",
      "Train Epoch: 24 [44800/60000 (75%)]\tTrain Loss: 0.561113\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tTrain Loss: 0.238208\n",
      "Train Epoch: 24 [57600/60000 (96%)]\tTrain Loss: 0.288894\n",
      "\n",
      "[EPOCH: 24], \tValidation Loss: 0.0094, \tValidation Accuracy: 91.00 % \n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tTrain Loss: 0.408949\n",
      "Train Epoch: 25 [6400/60000 (11%)]\tTrain Loss: 0.515290\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tTrain Loss: 0.587073\n",
      "Train Epoch: 25 [19200/60000 (32%)]\tTrain Loss: 0.340530\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tTrain Loss: 0.326968\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tTrain Loss: 0.330856\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tTrain Loss: 0.357094\n",
      "Train Epoch: 25 [44800/60000 (75%)]\tTrain Loss: 0.186769\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tTrain Loss: 0.419767\n",
      "Train Epoch: 25 [57600/60000 (96%)]\tTrain Loss: 0.312023\n",
      "\n",
      "[EPOCH: 25], \tValidation Loss: 0.0092, \tValidation Accuracy: 91.07 % \n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tTrain Loss: 0.552901\n",
      "Train Epoch: 26 [6400/60000 (11%)]\tTrain Loss: 0.187275\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tTrain Loss: 0.391031\n",
      "Train Epoch: 26 [19200/60000 (32%)]\tTrain Loss: 0.626402\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tTrain Loss: 0.337304\n",
      "Train Epoch: 26 [32000/60000 (53%)]\tTrain Loss: 0.277503\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tTrain Loss: 0.423584\n",
      "Train Epoch: 26 [44800/60000 (75%)]\tTrain Loss: 0.477283\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tTrain Loss: 0.182933\n",
      "Train Epoch: 26 [57600/60000 (96%)]\tTrain Loss: 0.372300\n",
      "\n",
      "[EPOCH: 26], \tValidation Loss: 0.0090, \tValidation Accuracy: 91.30 % \n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tTrain Loss: 0.402923\n",
      "Train Epoch: 27 [6400/60000 (11%)]\tTrain Loss: 0.253171\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tTrain Loss: 0.533235\n",
      "Train Epoch: 27 [19200/60000 (32%)]\tTrain Loss: 0.594307\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tTrain Loss: 0.393368\n",
      "Train Epoch: 27 [32000/60000 (53%)]\tTrain Loss: 0.433206\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tTrain Loss: 0.546454\n",
      "Train Epoch: 27 [44800/60000 (75%)]\tTrain Loss: 0.777022\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tTrain Loss: 0.580584\n",
      "Train Epoch: 27 [57600/60000 (96%)]\tTrain Loss: 0.509830\n",
      "\n",
      "[EPOCH: 27], \tValidation Loss: 0.0089, \tValidation Accuracy: 91.47 % \n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tTrain Loss: 0.245445\n",
      "Train Epoch: 28 [6400/60000 (11%)]\tTrain Loss: 0.183349\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tTrain Loss: 0.243936\n",
      "Train Epoch: 28 [19200/60000 (32%)]\tTrain Loss: 0.185845\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tTrain Loss: 0.499650\n",
      "Train Epoch: 28 [32000/60000 (53%)]\tTrain Loss: 0.605642\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tTrain Loss: 0.366972\n",
      "Train Epoch: 28 [44800/60000 (75%)]\tTrain Loss: 0.375006\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tTrain Loss: 0.182636\n",
      "Train Epoch: 28 [57600/60000 (96%)]\tTrain Loss: 0.338097\n",
      "\n",
      "[EPOCH: 28], \tValidation Loss: 0.0088, \tValidation Accuracy: 91.60 % \n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tTrain Loss: 0.653047\n",
      "Train Epoch: 29 [6400/60000 (11%)]\tTrain Loss: 0.564766\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tTrain Loss: 0.302159\n",
      "Train Epoch: 29 [19200/60000 (32%)]\tTrain Loss: 0.204943\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tTrain Loss: 0.323194\n",
      "Train Epoch: 29 [32000/60000 (53%)]\tTrain Loss: 0.160793\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tTrain Loss: 0.548196\n",
      "Train Epoch: 29 [44800/60000 (75%)]\tTrain Loss: 0.194301\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tTrain Loss: 0.258953\n",
      "Train Epoch: 29 [57600/60000 (96%)]\tTrain Loss: 0.388297\n",
      "\n",
      "[EPOCH: 29], \tValidation Loss: 0.0087, \tValidation Accuracy: 91.73 % \n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tTrain Loss: 0.317249\n",
      "Train Epoch: 30 [6400/60000 (11%)]\tTrain Loss: 0.483603\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tTrain Loss: 0.309015\n",
      "Train Epoch: 30 [19200/60000 (32%)]\tTrain Loss: 0.484407\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tTrain Loss: 0.326067\n",
      "Train Epoch: 30 [32000/60000 (53%)]\tTrain Loss: 0.135389\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tTrain Loss: 0.388153\n",
      "Train Epoch: 30 [44800/60000 (75%)]\tTrain Loss: 0.264371\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tTrain Loss: 0.287054\n",
      "Train Epoch: 30 [57600/60000 (96%)]\tTrain Loss: 0.599318\n",
      "\n",
      "[EPOCH: 30], \tValidation Loss: 0.0085, \tValidation Accuracy: 91.74 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' 8. MLP 학습 실행 '''\n",
    "''' 9. EPOCH 별 Test set Loss 및 Test set Accuracy 확인하기 '''\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    valid_loss, valid_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tValidation Loss: {:.4f}, \\tValidation Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, valid_loss, valid_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
