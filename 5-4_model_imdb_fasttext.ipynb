{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJGwgEKR_GPg"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3O6ttcHKrIq"
   },
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45748,
     "status": "ok",
     "timestamp": 1592897540907,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "1oJjy5xBJXAx",
    "outputId": "4bc884b4-a4cb-4702-9882-9c4ced75ad82"
   },
   "outputs": [],
   "source": [
    "# Data Setting\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                  fix_length = 500,\n",
    "                  tokenize=str.split,\n",
    "                  pad_first=True,\n",
    "                  pad_token='[PAD]',\n",
    "                  unk_token='[UNK]')\n",
    "\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(text_field = TEXT, \n",
    "                                             label_field = LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1657,
     "status": "ok",
     "timestamp": 1592897542573,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "34DoliQ6mdob",
    "outputId": "77297708-16c8-4127-b0b7-e0801cc48310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Length : 25000\n",
      "Test Data Length : 25000\n"
     ]
    }
   ],
   "source": [
    "# Data Length\n",
    "print(f'Train Data Length : {len(train_data.examples)}')\n",
    "print(f'Test Data Length : {len(test_data.examples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1646,
     "status": "ok",
     "timestamp": 1592897542574,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "3UNJJZE0mH75",
    "outputId": "fcf3af23-ed69-4d97-f4fa-27b169676aac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <torchtext.data.field.Field at 0x21de8be1630>,\n",
       " 'label': <torchtext.data.field.LabelField at 0x21de8be15f8>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Fields\n",
    "train_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1634,
     "status": "ok",
     "timestamp": 1592897542574,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "ViUZ13AM_HFQ",
    "outputId": "294ea99f-4fca-482f-d299-0a71da217ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Data Sample ----\n",
      "Input : \n",
      "Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they'll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it's like to be homeless? That is Goddard Bolt's lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet's on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can't step off the sidewalk. He's given the nickname Pepto by a vagrant after it's written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They're survivors. Bolt isn't. He's not used to reaching mutual agreements like he once did when being rich where it's fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn't necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it's like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don't know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others. \n",
      "\n",
      "Label : \n",
      "pos\n"
     ]
    }
   ],
   "source": [
    "# Data Sample\n",
    "print('---- Data Sample ----')\n",
    "print('Input : ')\n",
    "print(' '.join(vars(train_data.examples[1])['text']),'\\n')\n",
    "print('Label : ')\n",
    "print(vars(train_data.examples[1])['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pn4ddGIQLL_u"
   },
   "source": [
    "## Pre-processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpIQqgb_G41G"
   },
   "outputs": [],
   "source": [
    "def PreProcessingText(input_sentence):\n",
    "    input_sentence = input_sentence.lower() # 소문자화\n",
    "    input_sentence = re.sub('<[^>]*>', repl= ' ', string = input_sentence) # \"<br />\" 처리\n",
    "    input_sentence = re.sub('[!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~]', repl= ' ', string = input_sentence) # 특수문자 처리 (\"'\" 제외)\n",
    "    input_sentence = re.sub('\\s+', repl= ' ', string = input_sentence) # 연속된 띄어쓰기 처리\n",
    "    if input_sentence:\n",
    "        return input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cIqIf34a2SR"
   },
   "outputs": [],
   "source": [
    "for example in train_data.examples:\n",
    "    vars(example)['text'] = PreProcessingText(' '.join(vars(example)['text'])).split()\n",
    "    \n",
    "for example in test_data.examples:\n",
    "    vars(example)['text'] = PreProcessingText(' '.join(vars(example)['text'])).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iSucMR06LR8Y"
   },
   "source": [
    "## Making Vocab & Setting Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBI0uTQUSbdt"
   },
   "outputs": [],
   "source": [
    "model_config = {'emb_type' : 'fasttext', 'emb_dim' : 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 529277,
     "status": "ok",
     "timestamp": 1592898104969,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "8-y5MMRC7xRw",
    "outputId": "1fdd0c3d-a12e-4736-b447-976cabf1bff2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "# fasttext pre-trained \n",
    "\n",
    "# TEXT.build_vocab(train_data,\n",
    "#                  min_freq = 2, \n",
    "#                  max_size = None,\n",
    "#                  vectors = 'fasttext.en.300d')\n",
    "\n",
    "# 위와 같은 옵션으로 fasttext Pre-Trained vector를 가져올 수 있으나 현재 버그가 있어서 직접 다운받아 사용하는 방법으로 변경하였습니다.\n",
    "# ISSUE : https://github.com/pytorch/text/issues/634\n",
    "\n",
    "# 아래 코드는 jupyter notebook에서만 실행됩니다. python script로 실행할 경우에는 따로 다운받아서 준비해주시기 바랍니다.\n",
    "! wget 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8LGSnQIsAHcv"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "no vectors found at .vector_cache\\./wiki.en.vec",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8df2be455d00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fasttext pre-trained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfasttext_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./wiki.en.vec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m TEXT.build_vocab(train_data,\n",
      "\u001b[1;32mc:\\users\\justin\\101\\lib\\site-packages\\torchtext\\vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\justin\\101\\lib\\site-packages\\torchtext\\vocab.py\u001b[0m in \u001b[0;36mcache\u001b[1;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[0;32m    370\u001b[0m                             \u001b[0mtar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no vectors found at {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loading vectors from {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: no vectors found at .vector_cache\\./wiki.en.vec"
     ]
    }
   ],
   "source": [
    "# fasttext pre-trained \n",
    "from torchtext.vocab import Vectors\n",
    "fasttext_vectors = Vectors('./wiki.en.vec')\n",
    "\n",
    "TEXT.build_vocab(train_data,\n",
    "                 min_freq = 2, \n",
    "                 max_size = None,\n",
    "                 vectors = fasttext_vectors)\n",
    "\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "model_config['vocab_size'] = len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1102821,
     "status": "ok",
     "timestamp": 1592898684863,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "vt7ulofTn6U4",
    "outputId": "b1d4da6c-1ca7-41aa-efd0-026aac48e322"
   },
   "outputs": [],
   "source": [
    "# Vocabulary Info\n",
    "print(f'Vocab Size : {len(TEXT.vocab)}')\n",
    "\n",
    "print('Vocab Examples : ')\n",
    "for idx, (k, v) in enumerate(TEXT.vocab.stoi.items()):\n",
    "    if idx >= 10:\n",
    "        break    \n",
    "    print('\\t', k, v)\n",
    "\n",
    "print('---------------------------------')\n",
    "\n",
    "# Label Info\n",
    "print(f'Label Size : {len(LABEL.vocab)}')\n",
    "\n",
    "print('Lable Examples : ')\n",
    "for idx, (k, v) in enumerate(LABEL.vocab.stoi.items()):\n",
    "    print('\\t', k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1100464,
     "status": "ok",
     "timestamp": 1592898684864,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "s7dLNrxJMmEF",
    "outputId": "dfa8bc65-f246-4b7f-f5f7-ca7545542c00"
   },
   "outputs": [],
   "source": [
    "# Check embedding vectors\n",
    "TEXT.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zuSh9SlQLfGp"
   },
   "source": [
    "## Spliting Validation Data & Making Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbH-Rha8___V"
   },
   "outputs": [],
   "source": [
    "# Spliting Valid set\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(0),\n",
    "                                          split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKOfVNAwAJLU"
   },
   "outputs": [],
   "source": [
    "model_config['batch_size'] = 30\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=model_config['batch_size'],\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1105565,
     "status": "ok",
     "timestamp": 1592898694335,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "8OFTE-xAwJYb",
    "outputId": "2c2a405b-d81b-465d-f8d0-254e5d62fb50"
   },
   "outputs": [],
   "source": [
    "# Check batch data\n",
    "sample_for_check = next(iter(train_iterator))\n",
    "print(sample_for_check)\n",
    "print(sample_for_check.text)\n",
    "print(sample_for_check.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1102942,
     "status": "ok",
     "timestamp": 1592898694336,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "NU1fESnXyR9E",
    "outputId": "3d3324a5-2a49-4da0-bdbc-03ca5c02c155"
   },
   "outputs": [],
   "source": [
    "# Check reverting data\n",
    "print(' '.join([TEXT.vocab.itos[int(x)] for x in sample_for_check.text[0,:] if x not in [0,1]]))\n",
    "print(LABEL.vocab.itos[int(sample_for_check.label[0])]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZXWakE7MxU8"
   },
   "source": [
    "## Making Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CD2AK0NMAKr1"
   },
   "outputs": [],
   "source": [
    "class SentenceClassification(nn.Module):\n",
    "    def __init__(self, **model_config):\n",
    "        super(SentenceClassification, self).__init__()\n",
    "\n",
    "        if model_config['emb_type'] == 'glove' or 'fasttext':\n",
    "            self.emb = nn.Embedding(model_config['vocab_size'],\n",
    "                                    model_config['emb_dim'],\n",
    "                                    _weight = TEXT.vocab.vectors)\n",
    "        else:\n",
    "            self.emb = nn.Embedding(model_config['vocab_size'],\n",
    "                                    model_config['emb_dim'])\n",
    "        \n",
    "        self.bidirectional = model_config['bidirectional']\n",
    "        self.num_direction = 2 if model_config['bidirectional'] else 1\n",
    "        self.model_type = model_config['model_type'] \n",
    "\n",
    "        self.RNN = nn.RNN (input_size = model_config['emb_dim'],\n",
    "                           hidden_size = model_config['hidden_dim'],\n",
    "                           dropout = model_config['dropout'],\n",
    "                           bidirectional = model_config['bidirectional'],\n",
    "                           batch_first = model_config['batch_first'])\n",
    "        \n",
    "        self.LSTM= nn.LSTM(input_size = model_config['emb_dim'],\n",
    "                           hidden_size = model_config['hidden_dim'],\n",
    "                           dropout = model_config['dropout'],\n",
    "                           bidirectional = model_config['bidirectional'],\n",
    "                           batch_first = model_config['batch_first'])\n",
    "        \n",
    "        self.GRU = nn.GRU (input_size = model_config['emb_dim'],\n",
    "                           hidden_size = model_config['hidden_dim'],\n",
    "                           dropout = model_config['dropout'],\n",
    "                           bidirectional = model_config['bidirectional'],\n",
    "                           batch_first = model_config['batch_first'])\n",
    "    \n",
    "        self.fc = nn.Linear(model_config['hidden_dim'] * self.num_direction,\n",
    "                            model_config['output_dim'])\n",
    "        \n",
    "        self.drop = nn.Dropout(model_config['dropout'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        emb = self.emb(x) \n",
    "        # emb : (Batch_Size, Max_Seq_Length, Emb_dim)\n",
    "\n",
    "        if self.model_type == 'RNN':\n",
    "            output, hidden = self.RNN(emb) \n",
    "        elif self.model_type == 'LSTM':\n",
    "            output, (hidden, cell) = self.LSTM(emb)\n",
    "        elif self.model_type == 'GRU':\n",
    "            output, hidden = self.GRU(emb)\n",
    "        else:\n",
    "            raise NameError('Select model_type in [RNN, LSTM, GRU]')\n",
    "        \n",
    "        # output : (Batch_Size, Max_Seq_Length, Hidden_dim * num_direction) \n",
    "        # hidden : (Batch_Size, num_direction, Hidden_dim)\n",
    "        \n",
    "        last_output = output[:,-1,:]\n",
    "\n",
    "        # last_output : (Batch_Size, Hidden_dim * num_direction)\n",
    "        return self.fc(self.drop(last_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_3DNQR3M30p"
   },
   "source": [
    "### Checking feed-forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3VJ5BuHkm-4"
   },
   "outputs": [],
   "source": [
    "model_config.update(dict(batch_first = True,\n",
    "                         model_type = 'RNN',\n",
    "                         bidirectional = True,\n",
    "                         hidden_dim = 128,\n",
    "                         output_dim = 1,\n",
    "                         dropout = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWYjr7KQZxXu"
   },
   "outputs": [],
   "source": [
    "model = SentenceClassification(**model_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhGNULElZuI_"
   },
   "outputs": [],
   "source": [
    "predictions = model.forward(sample_for_check.text).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wabzuaD1AKjF"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdOXGw9ze-lI"
   },
   "outputs": [],
   "source": [
    "loss = loss_fn(predictions, sample_for_check.label)\n",
    "acc = binary_accuracy(predictions, sample_for_check.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1089630,
     "status": "ok",
     "timestamp": 1592898694341,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "s5OBri4AsPVy",
    "outputId": "97b784da-c03e-4a43-d228-ad932e419eab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1428, 0.0793, 0.2120, 0.1943, 0.1225, 0.3271, 0.0696, 0.0818, 0.0368,\n",
      "        0.2749, 0.2509, 0.1662, 0.0908, 0.1364, 0.1094, 0.0711, 0.0253, 0.0784,\n",
      "        0.0629, 0.1540, 0.0161, 0.0567, 0.1145, 0.0319, 0.1674, 0.1520, 0.1143,\n",
      "        0.0493, 0.0863, 0.1644], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "tensor(0.7038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) tensor(0.5000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rswNBOAzoImC"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCgs1fdcAKXF"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, iterator, optimizer, loss_fn, idx_epoch, **model_params):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train() \n",
    "    batch_size = model_params['batch_size']\n",
    "\n",
    "    for idx, batch in enumerate(iterator):\n",
    "        \n",
    "        # Initializing\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward \n",
    "        predictions = model(batch.text).squeeze()\n",
    "        loss = loss_fn(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        sys.stdout.write(\n",
    "                    \"\\r\" + f\"[Train] Epoch : {idx_epoch:^3}\"\\\n",
    "                    f\"[{(idx + 1) * batch_size} / {len(iterator) * batch_size} ({100. * (idx + 1) / len(iterator) :.4}%)]\"\\\n",
    "                    f\"  Loss: {loss.item():.4}\"\\\n",
    "                    f\"  Acc : {acc.item():.4}\"\\\n",
    "                    )\n",
    "\n",
    "        # Backward \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update Epoch Performance\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator) , epoch_acc/len(iterator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zqJ1gkFARwp"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, loss_fn):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = loss_fn(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIA_7QQzoLK1"
   },
   "source": [
    "### bi-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n6GtVuVFUHqz"
   },
   "outputs": [],
   "source": [
    "model_config['model_type'] = 'RNN'\n",
    "model = SentenceClassification(**model_config).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 310416,
     "status": "ok",
     "timestamp": 1592901996110,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "uTvlbDLnUHq2",
    "outputId": "6acc7122-b5fa-4594-f259-3629f788899e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Model name : bi-RNN_fasttext\n",
      "---------------------------------\n",
      "[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.5937  Acc : 0.7333\n",
      "\t Saved at 0-epoch\n",
      "\t Epoch : 0 | Train Loss : 0.5855 | Train Acc : 0.6843\n",
      "\t Epoch : 0 | Valid Loss : 0.6241 | Valid Acc : 0.7313\n",
      "[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.3864  Acc : 0.7667\n",
      "\t Saved at 1-epoch\n",
      "\t Epoch : 1 | Train Loss : 0.507 | Train Acc : 0.754\n",
      "\t Epoch : 1 | Valid Loss : 0.5609 | Valid Acc : 0.719\n",
      "[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.5854  Acc : 0.7\n",
      "\t Epoch : 2 | Train Loss : 0.38 | Train Acc : 0.8347\n",
      "\t Epoch : 2 | Valid Loss : 0.6707 | Valid Acc : 0.5851\n",
      "[Train] Epoch :  3 [20010 / 20010 (100.0%)]  Loss: 0.3719  Acc : 0.8333\n",
      "\t Epoch : 3 | Train Loss : 0.4988 | Train Acc : 0.7408\n",
      "\t Epoch : 3 | Valid Loss : 0.6833 | Valid Acc : 0.639\n",
      "[Train] Epoch :  4 [20010 / 20010 (100.0%)]  Loss: 0.7006  Acc : 0.6333\n",
      "\t Epoch : 4 | Train Loss : 0.3737 | Train Acc : 0.8292\n",
      "\t Epoch : 4 | Valid Loss : 0.7377 | Valid Acc : 0.6136\n"
     ]
    }
   ],
   "source": [
    "N_EPOCH = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
    "\n",
    "print('---------------------------------')\n",
    "print(f'Model name : {model_name}')\n",
    "print('---------------------------------')\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
    "    print('')\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
    "        print(f'\\t Saved at {epoch}-epoch')\n",
    "\n",
    "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
    "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 340010,
     "status": "ok",
     "timestamp": 1592902025714,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "akDRWiykUHq5",
    "outputId": "f5dab1e6-82aa-4524-fc81-f17b7f26171a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 0.5666 | Test Acc : 0.7163\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n",
    "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uxG4rgwTo8D7"
   },
   "source": [
    "### bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpW7ui5mUBTk"
   },
   "outputs": [],
   "source": [
    "model_config['model_type'] = 'LSTM'\n",
    "model = SentenceClassification(**model_config).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 400260,
     "status": "ok",
     "timestamp": 1592901654227,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "CDN-nLxJUBTo",
    "outputId": "807c3fd6-f1f5-407d-c2d4-6a49c637c070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Model name : bi-LSTM_fasttext\n",
      "---------------------------------\n",
      "[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.9103  Acc : 0.3333\n",
      "\t Saved at 0-epoch\n",
      "\t Epoch : 0 | Train Loss : 0.5922 | Train Acc : 0.6895\n",
      "\t Epoch : 0 | Valid Loss : 0.6722 | Valid Acc : 0.5856\n",
      "[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.436  Acc : 0.8\n",
      "\t Saved at 1-epoch\n",
      "\t Epoch : 1 | Train Loss : 0.3893 | Train Acc : 0.8246\n",
      "\t Epoch : 1 | Valid Loss : 0.3152 | Valid Acc : 0.8736\n",
      "[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.08638  Acc : 0.9333\n",
      "\t Epoch : 2 | Train Loss : 0.1778 | Train Acc : 0.9333\n",
      "\t Epoch : 2 | Valid Loss : 0.3201 | Valid Acc : 0.8787\n",
      "[Train] Epoch :  3 [20010 / 20010 (100.0%)]  Loss: 0.00928  Acc : 1.0\n",
      "\t Epoch : 3 | Train Loss : 0.07141 | Train Acc : 0.9772\n",
      "\t Epoch : 3 | Valid Loss : 0.3808 | Valid Acc : 0.8746\n",
      "[Train] Epoch :  4 [20010 / 20010 (100.0%)]  Loss: 0.07977  Acc : 0.9667\n",
      "\t Epoch : 4 | Train Loss : 0.0275 | Train Acc : 0.9925\n",
      "\t Epoch : 4 | Valid Loss : 0.4877 | Valid Acc : 0.8554\n"
     ]
    }
   ],
   "source": [
    "N_EPOCH = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
    "\n",
    "print('---------------------------------')\n",
    "print(f'Model name : {model_name}')\n",
    "print('---------------------------------')\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
    "    print('')\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
    "        print(f'\\t Saved at {epoch}-epoch')\n",
    "\n",
    "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
    "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 429432,
     "status": "ok",
     "timestamp": 1592901685673,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "d8qjmPU7UBTq",
    "outputId": "ee9cb713-d45a-4661-a333-477486cb22c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 0.321 | Test Acc : 0.8687\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n",
    "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfDGBCWRxnB_"
   },
   "source": [
    "### bi-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "khyItx4zxnCA"
   },
   "outputs": [],
   "source": [
    "model_config['model_type'] = 'GRU'\n",
    "model = SentenceClassification(**model_config).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 384682,
     "status": "ok",
     "timestamp": 1592901170802,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "om_7UjicxnCD",
    "outputId": "d1ea9e2d-407d-4fc6-b855-8491e6cb218c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Model name : bi-GRU_fasttext\n",
      "---------------------------------\n",
      "[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.4283  Acc : 0.8667\n",
      "\t Saved at 0-epoch\n",
      "\t Epoch : 0 | Train Loss : 0.4061 | Train Acc : 0.8075\n",
      "\t Epoch : 0 | Valid Loss : 0.2966 | Valid Acc : 0.8759\n",
      "[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.07912  Acc : 1.0\n",
      "\t Saved at 1-epoch\n",
      "\t Epoch : 1 | Train Loss : 0.1576 | Train Acc : 0.9424\n",
      "\t Epoch : 1 | Valid Loss : 0.2522 | Valid Acc : 0.8993\n",
      "[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.01315  Acc : 1.0\n",
      "\t Epoch : 2 | Train Loss : 0.04567 | Train Acc : 0.9851\n",
      "\t Epoch : 2 | Valid Loss : 0.3739 | Valid Acc : 0.8913\n",
      "[Train] Epoch :  3 [20010 / 20010 (100.0%)]  Loss: 0.001646  Acc : 1.0\n",
      "\t Epoch : 3 | Train Loss : 0.01101 | Train Acc : 0.9968\n",
      "\t Epoch : 3 | Valid Loss : 0.4561 | Valid Acc : 0.8895\n",
      "[Train] Epoch :  4 [20010 / 20010 (100.0%)]  Loss: 0.006299  Acc : 1.0\n",
      "\t Epoch : 4 | Train Loss : 0.006686 | Train Acc : 0.9979\n",
      "\t Epoch : 4 | Valid Loss : 0.5505 | Valid Acc : 0.8859\n"
     ]
    }
   ],
   "source": [
    "N_EPOCH = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
    "\n",
    "print('---------------------------------')\n",
    "print(f'Model name : {model_name}')\n",
    "print('---------------------------------')\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
    "    print('')\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
    "        print(f'\\t Saved at {epoch}-epoch')\n",
    "\n",
    "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
    "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32022,
     "status": "ok",
     "timestamp": 1592901217312,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "ZOL9MoBWxnCG",
    "outputId": "144a2d7b-7ca2-4194-832f-a00b0f791975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 0.278 | Test Acc : 0.8868\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n",
    "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEWK8wnkuEzA"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1991,
     "status": "ok",
     "timestamp": 1592902759994,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "x5VKyllQuReq",
    "outputId": "93c51e1d-d358-4467-dea2-e7ddf1e8e67f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config['model_type'] = 'GRU'\n",
    "model = SentenceClassification(**model_config).to(device)\n",
    "model.load_state_dict(torch.load(f\"./{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l35fvQw87-vg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPifO6k5ugGG"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    indexed = TEXT.numericalize(TEXT.pad([TEXT.tokenize(PreProcessingText(sentence))]))\n",
    "    input_data = torch.LongTensor(indexed).to(device)\n",
    "    prediction = torch.sigmoid(model(input_data))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1771,
     "status": "ok",
     "timestamp": 1592902765787,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "gY4lDbr-xB7V",
    "outputId": "985a1922-379f-4321-87fa-9ff34986a3c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9115353226661682"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = 'this movie is FUN'\n",
    "predict_sentiment(model = model, sentence = test_sentence)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM6aaEyBN0Vx0y5s7xKIAHb",
   "collapsed_sections": [],
   "name": "6-4_model_imdb_fasttext.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
